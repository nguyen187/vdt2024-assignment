version: '3.6'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION}
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    user: root
      
    volumes:
      - ./zookeeper/zkdata:/var/lib/zookeeper/data
      - ./zookeeper/zklog:/var/lib/zookeeper/log
    ports:
     - "2181:2181"
    container_name: zookeeper
    healthcheck:
      test: nc -z zookeeper 2181 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
        - my_persistent_network
  broker01:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    depends_on:
      zookeeper:
        condition: service_healthy
    user: root
    container_name: broker01
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT_HOST://broker01:9092,PLAINTEXT://broker01:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_HOST://localhost:9092,PLAINTEXT://broker01:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_JMX_PORT: 9090
      KAFKA_LOG_DIRS: /var/log/kafka
      KAFKA_NUM_PARTITIONS: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_ENABLE: 'false'
    volumes:
      - ./kafka/data1:/var/lib/kafka/data
    ports:
      - 9092:9092
    mem_limit: ${MEM_LIMIT}
    healthcheck:
      test: nc -z broker01 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network
  broker02:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    depends_on:
      zookeeper:
        condition: service_healthy
    
    container_name: broker02
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT_HOST://broker02:9093,PLAINTEXT://broker02:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_HOST://localhost:9093,PLAINTEXT://broker02:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_JMX_PORT: 9090
      KAFKA_LOG_DIRS: /var/log/kafka
      KAFKA_NUM_PARTITIONS: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_ENABLE: 'false'
    volumes:
      - ./kafka/data2:/var/lib/kafka/data
    user: root
    
    ports:
      - 9093:9093
    mem_limit: ${MEM_LIMIT}
    healthcheck:
      test: nc -z broker02 9093 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    depends_on:
      broker01:
        condition: service_healthy
      broker02:
        condition: service_healthy
    
    environment:
      KAFKA_CLUSTERS_0_NAME: vdt-kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker01:9093,broker02:9094
      KAFKA_CLUSTERS_0_METRICS_PORT: 9090
      # KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    mem_limit: ${MEM_LIMIT}
    healthcheck:
      test: nc -z kafka-ui 8080 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network
      
# version control for nifi flows
  registry:
      # hostname: myregistry
      container_name: registry_container_persistent
      image: 'apache/nifi-registry:1.15.0' # latest image as of 2021-11-09.
      restart: on-failure
      user: root
      ports:
          - "18080:18080"

      environment:
          - LOG_LEVEL=INFO
          - NIFI_REGISTRY_DB_DIR=/opt/nifi-registry/nifi-registry-current/database
          - NIFI_REGISTRY_FLOW_PROVIDER=file
          - NIFI_REGISTRY_FLOW_STORAGE_DIR=/opt/nifi-registry/nifi-registry-current/flow_storage
      volumes:
          - ./nifi/registry/database:/opt/nifi-registry/nifi-registry-current/database
          - ./nifi/registry/flow_storage1:/opt/nifi-registry/nifi-registry-current/flow_storage
      networks:
          - my_persistent_network
# data extraction, transformation and load service
  nifi:
      # hostname: mynifi
      container_name: nifi_container_persistent
      image: 'apache/nifi:1.14.0'  # latest image as of 2021-11-09.
      restart: on-failure
      user: root
      ports:
          - '8091:8080'
      environment:
          - NIFI_WEB_HTTP_PORT=8080
          - NIFI_CLUSTER_IS_NODE=true
          - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
          - NIFI_ZK_CONNECT_STRING=zookeeper:2181
          - NIFI_ELECTION_MAX_WAIT=30 sec
          - NIFI_SENSITIVE_PROPS_KEY='12345678901234567890A'
      
      volumes:
          - ./nifi/database_repository:/opt/nifi/nifi-current/database_repository
          - ./nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
          - ./nifi/content_repository:/opt/nifi/nifi-current/content_repository
          - ./nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
          - ./nifi/state:/opt/nifi/nifi-current/state
          - ./nifi/logs:/opt/nifi/nifi-current/logs
          # uncomment the next line after copying the /conf directory from the container to your local directory to persist NiFi flows
          - ./nifi/conf:/opt/nifi/nifi-current/conf

      healthcheck:
          test: "${DOCKER_HEALTHCHECK_TEST:-curl localhost:8091/nifi/}"
          interval: "60s"
          timeout: "3s"
          start_period: "5s"
          retries: 5    
      networks:
          - my_persistent_network
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9010:9000
    volumes:
      - ./hadoop/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    env_file:
      - ./hadoop.env
    networks:
          - my_persistent_network

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - ./hadoop/datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
    ports:
      - "9864:9864"
    env_file:
      - ./hadoop.env
    networks:
          - my_persistent_network

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - ./hadoop/historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: spark-master
    
    depends_on:
      - namenode
      - datanode
    
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - ./spark/conf:/spark/conf
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_DRIVER_MAXRESULTSIZE=0
    networks:
      - my_persistent_network

  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_MEMORY=2g
    networks:
      - my_persistent_network


networks:
  my_persistent_network:
    driver: bridge